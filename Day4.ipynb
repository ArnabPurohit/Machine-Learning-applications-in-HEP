{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2dim Gaussians : The training data\n",
    "# centered at (1,1)\n",
    "x1_label0 = np.random.normal(1,2,(1500,1))\n",
    "x2_label0 = np.random.normal(1,1,(1500,1))\n",
    "# centered at (5,4)\n",
    "x1_label1 = np.random.normal(5,1,(1500,1))\n",
    "x2_label1 = np.random.normal(4,2,(1500,1))\n",
    "# centered at (8,0)\n",
    "x1_label2 = np.random.normal(8,2,(1500,1))\n",
    "x2_label2 = np.random.normal(0,1,(1500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    }
   ],
   "source": [
    "# Show the plot of the data created above\n",
    "plt.scatter(x1_label0,x2_label0,c=\"r\",marker=\"o\",s=60)\n",
    "plt.scatter(x1_label1,x2_label1,c=\"g\",marker=\"*\",s=60)\n",
    "plt.scatter(x1_label2,x2_label2,c=\"b\",marker=\"o\",s=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack the (x1,x2) for the data: horizantol stacking\n",
    "xs_label0 = np.hstack((x1_label0,x2_label0))\n",
    "xs_label1 = np.hstack((x1_label1,x2_label1))\n",
    "xs_label2 = np.hstack((x1_label2,x2_label2))\n",
    "# stacke labels 0, 1 and 2 vertically\n",
    "xs = np.vstack((xs_label0,xs_label1,xs_label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.matrix([[1,0,0]]*len(xs_label0)+[[0,1,0]]*len(xs_label1)+[[0,0,1]]*len(xs_label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar = np.arange(len(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = xs[ar,:]\n",
    "labels = labels[ar,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2dim Gaussians : The test data\n",
    "# centered at (1,1)\n",
    "test_x1_label0 = np.random.normal(1,2,(50,1))\n",
    "test_x2_label0 = np.random.normal(1,1,(50,1))\n",
    "# centered at (5,4)\n",
    "test_x1_label1 = np.random.normal(5,1,(50,1))\n",
    "test_x2_label1 = np.random.normal(4,2,(50,1))\n",
    "# centered at (8,0)\n",
    "test_x1_label2 = np.random.normal(8,2,(50,1))\n",
    "test_x2_label2 = np.random.normal(0,1,(50,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack the (x1,x2) for the test data: horizantol stacking\n",
    "test_xs_label0 = np.hstack((test_x1_label0,test_x2_label0))\n",
    "test_xs_label1 = np.hstack((test_x1_label1,test_x2_label1))\n",
    "test_xs_label2 = np.hstack((test_x1_label2,test_x2_label2))\n",
    "# stacke labels 0, 1 and 2 vertically\n",
    "test_xs = np.vstack((test_xs_label0,test_xs_label1,test_xs_label2))\n",
    "test_labels = np.matrix([[1,0,0]]*len(test_xs_label0)+[[0,1,0]]*len(test_xs_label1)+[[0,0,1]]*len(test_xs_label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size,num_features = xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "batch_size = 200\n",
    "# number of labels\n",
    "num_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\",shape=[None,num_features])\n",
    "Y = tf.placeholder(\"float\",shape=[None,num_labels])\n",
    "W = tf.Variable(tf.zeros([num_features,num_labels])) \n",
    "B = tf.Variable(tf.zeros([num_labels]))\n",
    "Y_model = tf.nn.softmax(tf.matmul(X,W)+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_sum(Y*tf.log(Y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(Y_model,1),tf.argmax(Y,1))\n",
    "accuracy =tf.reduce_mean(tf.cast(correct_prediction,\"float\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 219.723\n",
      "90 61.7411\n",
      "180 52.0074\n",
      "270 47.9355\n",
      "360 45.6565\n",
      "450 44.1783\n",
      "540 43.1306\n",
      "630 42.3431\n",
      "720 41.7262\n",
      "810 41.228\n",
      "900 40.8162\n",
      "990 40.4695\n",
      "1080 40.1734\n",
      "1170 39.9174\n",
      "1260 39.694\n",
      "1350 39.4972\n",
      "1440 39.3228\n",
      "1530 39.1671\n",
      "1620 39.0275\n",
      "1710 38.9017\n",
      "1800 38.7878\n",
      "1890 38.6842\n",
      "1980 38.5899\n",
      "2070 38.5035\n",
      "2160 38.4244\n",
      "2250 38.3515\n",
      "2340 38.2844\n",
      "2430 38.2224\n",
      "2520 38.165\n",
      "2610 38.1118\n",
      "2700 38.0623\n",
      "2790 38.0163\n",
      "2880 37.9734\n",
      "2970 37.9333\n",
      "3060 37.8958\n",
      "3150 37.8608\n",
      "3240 37.8279\n",
      "3330 37.7971\n",
      "3420 37.7681\n",
      "3510 37.7408\n",
      "3600 37.7152\n",
      "3690 37.691\n",
      "3780 37.6683\n",
      "3870 37.6468\n",
      "3960 37.6264\n",
      "4050 37.6072\n",
      "4140 37.5891\n",
      "4230 37.5719\n",
      "4320 37.5556\n",
      "4410 37.5401\n",
      "4500 37.5254\n",
      "4590 37.5115\n",
      "4680 37.4983\n",
      "4770 37.4857\n",
      "4860 37.4738\n",
      "4950 37.4624\n",
      "5040 37.4516\n",
      "5130 37.4413\n",
      "5220 37.4315\n",
      "5310 37.4221\n",
      "5400 37.4132\n",
      "5490 37.4047\n",
      "5580 37.3966\n",
      "5670 37.3888\n",
      "5760 37.3814\n",
      "5850 37.3744\n",
      "5940 37.3676\n",
      "6030 37.3611\n",
      "6120 37.355\n",
      "6210 37.3491\n",
      "6300 37.3434\n",
      "6390 37.338\n",
      "6480 37.3328\n",
      "6570 37.3278\n",
      "6660 37.3231\n",
      "6750 37.3185\n",
      "6840 37.3142\n",
      "6930 37.31\n",
      "7020 37.306\n",
      "7110 37.3021\n",
      "7200 37.2984\n",
      "7290 37.2949\n",
      "7380 37.2915\n",
      "7470 37.2883\n",
      "7560 37.2851\n",
      "7650 37.2821\n",
      "7740 37.2793\n",
      "7830 37.2765\n",
      "7920 37.2738\n",
      "8010 37.2713\n",
      "8100 37.2688\n",
      "8190 37.2665\n",
      "8280 37.2642\n",
      "8370 37.262\n",
      "8460 37.2599\n",
      "8550 37.2579\n",
      "8640 37.256\n",
      "8730 37.2541\n",
      "8820 37.2523\n",
      "8910 37.2506\n",
      "9000 37.249\n",
      "9090 37.2474\n",
      "9180 37.2459\n",
      "9270 37.2444\n",
      "9360 37.243\n",
      "9450 37.2416\n",
      "9540 37.2403\n",
      "9630 37.239\n",
      "9720 37.2378\n",
      "9810 37.2366\n",
      "9900 37.2355\n",
      "9990 37.2344\n",
      "10080 37.2334\n",
      "10170 37.2324\n",
      "10260 37.2314\n",
      "10350 37.2305\n",
      "10440 37.2296\n",
      "10530 37.2287\n",
      "10620 37.2279\n",
      "10710 37.2271\n",
      "10800 37.2263\n",
      "10890 37.2256\n",
      "10980 37.2249\n",
      "11070 37.2242\n",
      "11160 37.2235\n",
      "11250 37.2229\n",
      "11340 37.2223\n",
      "11430 37.2217\n",
      "11520 37.2211\n",
      "11610 37.2206\n",
      "11700 37.22\n",
      "11790 37.2195\n",
      "11880 37.219\n",
      "11970 37.2186\n",
      "12060 37.2181\n",
      "12150 37.2177\n",
      "12240 37.2172\n",
      "12330 37.2168\n",
      "12420 37.2164\n",
      "12510 37.216\n",
      "12600 37.2157\n",
      "12690 37.2153\n",
      "12780 37.215\n",
      "12870 37.2147\n",
      "12960 37.2143\n",
      "13050 37.214\n",
      "13140 37.2137\n",
      "13230 37.2135\n",
      "13320 37.2132\n",
      "13410 37.2129\n",
      "13500 37.2127\n",
      "13590 37.2124\n",
      "13680 37.2122\n",
      "13770 37.212\n",
      "13860 37.2118\n",
      "13950 37.2115\n",
      "14040 37.2113\n",
      "14130 37.2111\n",
      "14220 37.2109\n",
      "14310 37.2108\n",
      "14400 37.2106\n",
      "14490 37.2104\n",
      "14580 37.2103\n",
      "14670 37.2101\n",
      "14760 37.2099\n",
      "14850 37.2098\n",
      "14940 37.2097\n",
      "15030 37.2095\n",
      "15120 37.2094\n",
      "15210 37.2093\n",
      "15300 37.2091\n",
      "15390 37.209\n",
      "15480 37.2089\n",
      "15570 37.2088\n",
      "15660 37.2087\n",
      "15750 37.2086\n",
      "15840 37.2085\n",
      "15930 37.2084\n",
      "16020 37.2083\n",
      "16110 37.2082\n",
      "16200 37.2081\n",
      "16290 37.2081\n",
      "16380 37.208\n",
      "16470 37.2079\n",
      "16560 37.2078\n",
      "16650 37.2078\n",
      "16740 37.2077\n",
      "16830 37.2076\n",
      "16920 37.2076\n",
      "17010 37.2075\n",
      "17100 37.2074\n",
      "17190 37.2074\n",
      "17280 37.2073\n",
      "17370 37.2073\n",
      "17460 37.2072\n",
      "17550 37.2072\n",
      "17640 37.2071\n",
      "17730 37.2071\n",
      "17820 37.2071\n",
      "17910 37.207\n",
      "18000 37.207\n",
      "18090 37.2069\n",
      "18180 37.2069\n",
      "18270 37.2069\n",
      "18360 37.2068\n",
      "18450 37.2068\n",
      "18540 37.2068\n",
      "18630 37.2067\n",
      "18720 37.2067\n",
      "18810 37.2067\n",
      "18900 37.2066\n",
      "18990 37.2066\n",
      "19080 37.2066\n",
      "19170 37.2066\n",
      "19260 37.2065\n",
      "19350 37.2065\n",
      "19440 37.2065\n",
      "19530 37.2065\n",
      "19620 37.2065\n",
      "19710 37.2064\n",
      "19800 37.2064\n",
      "19890 37.2064\n",
      "19980 37.2064\n",
      "20070 37.2064\n",
      "20160 37.2064\n",
      "20250 37.2063\n",
      "20340 37.2063\n",
      "20430 37.2063\n",
      "20520 37.2063\n",
      "20610 37.2063\n",
      "20700 37.2063\n",
      "20790 37.2062\n",
      "20880 37.2062\n",
      "20970 37.2062\n",
      "21060 37.2062\n",
      "21150 37.2062\n",
      "21240 37.2062\n",
      "21330 37.2062\n",
      "21420 37.2062\n",
      "21510 37.2061\n",
      "21600 37.2061\n",
      "21690 37.2061\n",
      "21780 37.2061\n",
      "21870 37.2061\n",
      "21960 37.2061\n",
      "22050 37.2061\n",
      "22140 37.2061\n",
      "22230 37.2061\n",
      "22320 37.2061\n",
      "22410 37.206\n",
      "[[-1.34430528  0.20931414  1.135041  ]\n",
      " [-0.17559059  0.90020698 -0.72460866]]\n",
      "[ 6.20681238 -1.41499209 -4.79173899]\n",
      "0.933333\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for step in range(training_epochs*train_size//batch_size):\n",
    "        offset = (step*batch_size)%train_size\n",
    "        batch_xs = xs[offset:offset+batch_size,:]\n",
    "        batch_labels = labels[offset:offset+batch_size]\n",
    "        err,_ = sess.run([cost,training_op],feed_dict={X:batch_xs,Y:batch_labels})\n",
    "        if(step%90 ==0):\n",
    "            print(step,err)\n",
    "    \n",
    "    W_val = sess.run(W)\n",
    "    B_val = sess.run(B)\n",
    "    print(W_val)\n",
    "    print(B_val)\n",
    "    #print (accuracy.eval())\n",
    "    acc = sess.run(accuracy,feed_dict={X:test_xs,Y:test_labels})\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
